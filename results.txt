Total number of XMI we went through:
2418

Working ones (excluding duplicates, issues, etc.):
93

Done - First iteration: 
66 

Done - Second Iteration:
17 

Done - Third iteration:
5 

Fails - Third iteration:
5

Duplicates of working ones:
47

Not class diagrams (but could be imported into Modelio):
6

---------------------------------------------------------------------------

Ask about:
1GRAAnnotationModel, GRAAnnotationModel, bmm, jrlib --> too large, forced to click "continue generating" button. 
GPT would never be able to complete them, bug when forced to click the button, loses focus, doesn't save automatically.

api --> below 200kb in size (the size we went for), but still too large for GPT (message too long)

NIEM-Reference-common-nga --> unable to get GPT to follow instructions

NIEM-Reference-external-cap --> mentioned previously, unreadable/unusable

1modelio_no_class_name_test --> no real data in it

---------------------------------------------------------------------------
Issues we've discovered along the way:
Files are too large even when below 200kb from the dataset
Files lacking a name, bothUwithin XMI and the file itself
Files trigger responses from GPT which are too long, forcing an additional manual click
File in different language/alphabet, breaking the pipeline (russian)
File with invalid name (Use%20Cases)
Some files can be imported into Modelio, but aren't class diagrams (unusable to us)
A lot of duplicates within the dataset
GPT sometimes struggles to understand the given instruction, ignoring it and adding comments when it's told not to
as well as not producing a comment for [[STARTEND]] completely. 
Formatting isn't perfect, beyond compare should be used in conjuction with the output files/XMI. 
---------------------------------------------------------------------------
errors within the generation - Done after second iteration:

---------------------------------------------------------------------------
errors within the generation - Done after third iteration, second iteration:

---------------------------------------------------------------------------
errors within the generation - Failed after third iteration, second iteration:


---------------------------------------------------------------------------
errors within the generation - Done after third iteration, third iteration:


---------------------------------------------------------------------------
errors within the generation - Failed after third iteration, third iteration:
The variable X has the wrong type. / The attribute BindingCode has the wrong type. - 6
The class X is missing. - 2
The class X is missing a class. - 1
The attribute X is missing an enum instance. - 3
The relation cardinality was not translated correctly for the attribute X. - 27
The class X extends the wrong class. - 6
The attribute X has the wrong name. - 1
The attribute X is missing an enum instance. - 3
The function X has the wrong return type. - 2
The extends statement of X is incorrect. - 8

---------------------------------------------------------------------------



Total list:


---------------------------------------------------------------------------
Total list - Second iteration:


---------------------------------------------------------------------------
Total list - Third Iteration:





Notable conclusions:
ChatGPT struggles primarily with reading relation cardinality from XMI. Noticeably though, most of the issues (23), were from one file. 
While executing, it has been noticable that depending on instance GPT has either been smarter or "dumber" (things it got correct previously is now wrong etc.). 
Overall the results are as to be expected, where it could solve most on the first attempt (72.5%), a smaller set on the second (18.7%), and the smallest on the third (5.5%), while also failing some (3.3%).
In terms of the difficulty of the XMI, it varies substantially. It can be stated that GPT struggles with some longer XMI. 








